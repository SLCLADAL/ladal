m2.lrm
anova(m2.lrm)
# model validation (remove # to activate: output too long for website)
m7.lrm <- lrm(EH ~ (Age + Gender + Ethnicity)^3, data = blrdata, x = T, y = T, linear.predictors = T)
# validate(m7.lrm, bw = T, B = 200)
pentrace(m2.lrm, seq(0, 0.8, by = 0.05)) # determine penalty
lr.glm <- m2.blr # rename final minimal adequate glm model
lr.lrm <- m2.lrm # rename final minimal adequate lrm model
modelChi <- lr.glm$null.deviance - lr.glm$deviance
chidf <- lr.glm$df.null - lr.glm$df.residual
chisq.prob <- 1 - pchisq(modelChi, chidf)
modelChi
chidf
chisq.prob
anova(m0.glm, lr.glm, test = "Chi") # Model Likelihood Ratio Test
# calculate pseudo R^2
# number of cases
ncases <- length(fitted(lr.glm))
R2.hl <- modelChi / lr.glm$null.deviance
R.cs <- 1 - exp((lr.glm$deviance - lr.glm$null.deviance) / ncases)
R.n <- R.cs / (1 - (exp(-(lr.glm$null.deviance / ncases))))
# function for extracting pseudo-R^2
logisticPseudoR2s <- function(LogModel) {
dev <- LogModel$deviance
nullDev <- LogModel$null.deviance
modelN <- length(LogModel$fitted.values)
R.l <- 1 - dev / nullDev
R.cs <- 1 - exp(-(nullDev - dev) / modelN)
R.n <- R.cs / (1 - (exp(-(nullDev / modelN))))
cat("Pseudo R^2 for logistic regression\n")
cat("Hosmer and Lemeshow R^2  ", round(R.l, 3), "\n")
cat("Cox and Snell R^2        ", round(R.cs, 3), "\n")
cat("Nagelkerke R^2           ", round(R.n, 3), "\n")
}
logisticPseudoR2s(lr.glm)
# extract the confidence intervals for the coefficients
confint(lr.glm)
exp(lr.glm$coefficients) # odds ratios
exp(confint(lr.glm)) # confidence intervals of the odds ratios
# create variable with contains the prediction of the model
blrdata <- blrdata %>%
dplyr::mutate(
Prediction = predict(lr.glm, type = "response"),
Prediction = ifelse(Prediction > .5, 1, 0),
Prediction = factor(Prediction, levels = c("0", "1")),
EH = factor(EH, levels = c("0", "1"))
)
# create a confusion matrix with compares observed against predicted values
caret::confusionMatrix(blrdata$Prediction, blrdata$EH)
# predicted probability
efp1 <- plot_model(lr.glm, type = "pred", terms = c("Age"), axis.lim = c(0, 1))
# predicted percentage
efp2 <- plot_model(lr.glm, type = "pred", terms = c("Gender"), axis.lim = c(0, 1))
grid.arrange(efp1, efp2, nrow = 1)
sjPlot::plot_model(lr.glm, type = "pred", terms = c("Age", "Gender"), axis.lim = c(0, 1)) +
theme(legend.position = "top") +
labs(x = "", y = "Predicted Probabilty of eh", title = "") +
scale_color_manual(values = c("gray20", "gray70"))
vif(lr.glm)
mean(vif(lr.glm))
infl <- influence.measures(lr.glm) # calculate influence statistics
blrdata <- data.frame(blrdata, infl[[1]], infl[[2]]) # add influence statistics
# function to evaluate sample size
smplesz <- function(x) {
ifelse((length(x$fitted) < (104 + ncol(summary(x)$coefficients) - 1)) == TRUE,
return(
paste("Sample too small: please increase your sample by ",
104 + ncol(summary(x)$coefficients) - 1 - length(x$fitted),
" data points",
collapse = ""
)
),
return("Sample size sufficient")
)
}
# apply unction to model
smplesz(lr.glm)
sjPlot::tab_model(lr.glm)
# load function
source("https://slcladal.github.io/rscripts/blrsummary.r")
# calculate accuracy
predict.acc <- caret::confusionMatrix(blrdata$Prediction, blrdata$EH)
predict.acc <- predict.acc[3]$overall[[1]]
# create summary table
blrsummarytb <- blrsummary(lr.glm, lr.lrm, predict.acc)
# inspect data
blrsummarytb %>%
as.data.frame() %>%
tibble::rownames_to_column("Statistics") %>%
flextable() %>%
flextable::set_table_properties(width = .75, layout = "autofit") %>%
flextable::theme_zebra() %>%
flextable::fontsize(size = 12) %>%
flextable::fontsize(size = 12, part = "header") %>%
flextable::align_text_col(align = "center") %>%
flextable::set_caption(caption = "Results of the binomial logistic regression analysis.") %>%
flextable::border_outer()
report::report(lr.glm)
# load data
ordata <- base::readRDS(url("https://slcladal.github.io/data/ord.rda", "rb")) %>%
dplyr::rename(
Recommend = 1,
Internal = 2,
Exchange = 3,
FinalScore = 4
) %>%
dplyr::mutate(FinalScore = round(FinalScore, 2))
# inspect data
ordata %>%
as.data.frame() %>%
head(15) %>%
flextable() %>%
flextable::set_table_properties(width = .75, layout = "autofit") %>%
flextable::theme_zebra() %>%
flextable::fontsize(size = 12) %>%
flextable::fontsize(size = 12, part = "header") %>%
flextable::align_text_col(align = "center") %>%
flextable::set_caption(caption = "First 15 rows of the ordata.") %>%
flextable::border_outer()
# relevel data
ordata <- ordata %>%
dplyr::mutate(Recommend = factor(Recommend,
levels = c("unlikely", "somewhat likely", "very likely"),
labels = c("unlikely", "somewhat likely", "very likely")
)) %>%
dplyr::mutate(Exchange = ifelse(Exchange == 1, "Exchange", "NoExchange")) %>%
dplyr::mutate(Internal = ifelse(Internal == 1, "Internal", "External"))
## three way cross tabs (xtabs) and flatten the table
ftable(xtabs(~ Exchange + Recommend + Internal, data = ordata))
summary(ordata$FinalScore)
sd(ordata$FinalScore)
# visualize data
ggplot(ordata, aes(x = Recommend, y = FinalScore)) +
geom_boxplot(size = .75) +
geom_jitter(alpha = .5) +
facet_grid(Exchange ~ Internal, margins = TRUE) +
theme(axis.text.x = element_text(angle = 45, hjust = 1, vjust = 1))
# fit ordered logit model and store results 'm'
m.or <- polr(Recommend ~ Internal + Exchange + FinalScore, data = ordata, Hess = TRUE)
# summarize model
summary(m.or)
## store table
(ctable <- coef(summary(m.or)))
## calculate and store p values
p <- pnorm(abs(ctable[, "t value"]), lower.tail = FALSE) * 2
## combined table
(ctable <- cbind(ctable, "p value" = p))
# extract profiled confidence intervals
ci <- confint(m.or)
# calculate odds ratios and combine them with profiled CIs
exp(cbind(OR = coef(m.or), ci))
# plot poisson
Count <- 1:10
Lambda1 <- dpois(Count, 1)
Lambda2 <- dpois(Count, 2)
Lambda3 <- dpois(Count, 3)
Lambda4 <- dpois(Count, 4)
Lambda5 <- dpois(Count, 5)
pdata <- data.frame(Count, Lambda1, Lambda2, Lambda3, Lambda4, Lambda5)
pdata <- pdata %>%
dplyr::group_by(Count) %>%
tidyr::gather(Lambda, Value, Lambda1:Lambda5) %>%
dplyr::mutate(Lambda = str_replace_all(Lambda, "Lambda", "")) %>%
dplyr::mutate(Lambda = factor(Lambda))
# plot poisson with different lambdas
ggplot(pdata, aes(x = Count, y = Value, color = Lambda)) +
geom_smooth(alpha = .5, se = F) +
guides(color = guide_legend(override.aes = list(fill = NA))) +
theme_set(theme_bw(base_size = 10)) +
theme(legend.position = "top") +
scale_colour_manual(values = c(
"goldenrod2", "gray40", "blue",
"indianred4", "gray80"
), name = "Lambda") +
labs(x = "Number of Instances") +
scale_x_continuous(breaks = 1:10, labels = 1:10) +
scale_y_continuous(name = "Probability", limits = c(0, .4))
# load data
poissondata <- base::readRDS(url("https://slcladal.github.io/data/prd.rda", "rb"))
# inspect data
poissondata %>%
as.data.frame() %>%
head(15) %>%
flextable() %>%
flextable::set_table_properties(width = .75, layout = "autofit") %>%
flextable::theme_zebra() %>%
flextable::fontsize(size = 12) %>%
flextable::fontsize(size = 12, part = "header") %>%
flextable::align_text_col(align = "center") %>%
flextable::set_caption(caption = "First 15 rows of the poissondata.") %>%
flextable::border_outer()
# process data
poissondata <- poissondata %>%
mutate(Id = factor(Id, levels = 1:200, labels = 1:200))
# inspect data
str(poissondata)
# output the results
gf <- vcd::goodfit(poissondata$Pauses,
type = "poisson",
method = "ML"
)
# inspect results
summary(gf)
plot(gf, main = "Count data vs Poisson distribution")
# check homogeneity
leveneTest(poissondata$Pauses, poissondata$Language, center = mean)
# extract mean and standard deviation
with(poissondata, tapply(Pauses, Language, function(x) {
sprintf("M (SD) = %1.2f (%1.2f)", mean(x), sd(x))
}))
# plot data
ggplot(poissondata, aes(Pauses, fill = Language)) +
geom_histogram(binwidth = .5, position = "dodge") +
scale_fill_manual(values = c("gray30", "gray50", "gray70"))
# calculate Poisson regression
m1.poisson <- glm(Pauses ~ Language + Alcohol, family = "poisson", data = poissondata)
# inspect model
summary(m1.poisson)
# calculate model
cov.m1 <- sandwich::vcovHC(m1.poisson, type = "HC0")
# extract standard error
std.err <- sqrt(diag(cov.m1))
# extract robust estimates
r.est <- cbind(
Estimate = coef(m1.poisson),
"Robust SE" = std.err,
"Pr(>|z|)" = 2 * pnorm(abs(coef(m1.poisson) / std.err),
lower.tail = FALSE
),
LL = coef(m1.poisson) - 1.96 * std.err,
UL = coef(m1.poisson) + 1.96 * std.err
)
# inspect data
r.est
with(m1.poisson, cbind(
res.deviance = deviance, df = df.residual,
p = pchisq(deviance, df.residual, lower.tail = FALSE)
))
# remove Language from the model
m2.poisson <- update(m1.poisson, . ~ . - Language)
# check if dropping Language causes a significant decrease in model fit
anova(m2.poisson, m1.poisson, test = "Chisq")
# get estimates
s <- msm::deltamethod(
list(~ exp(x1), ~ exp(x2), ~ exp(x3), ~ exp(x4)),
coef(m1.poisson), cov.m1
)
# exponentiate old estimates dropping the p values
rexp.est <- exp(r.est[, -3])
# replace SEs with estimates for exponentiated coefficients
rexp.est[, "Robust SE"] <- s
# display results
rexp.est
# extract predicted values
(s1 <- data.frame(
Alcohol = mean(poissondata$Alcohol),
Language = factor(1:3, levels = 1:3, labels = names(table(poissondata$Language)))
))
# show results
predict(m1.poisson, s1, type = "response", se.fit = TRUE)
## calculate and store predicted values
poissondata$Predicted <- predict(m1.poisson, type = "response")
## order by program and then by math
poissondata <- poissondata[with(poissondata, order(Language, Alcohol)), ]
## create the plot
ggplot(poissondata, aes(x = Alcohol, y = Predicted, colour = Language)) +
geom_point(aes(y = Pauses),
alpha = .5,
position = position_jitter(h = .2)
) +
geom_line(size = 1) +
labs(x = "Alcohol (ml)", y = "Expected number of pauses") +
scale_color_manual(values = c("gray30", "gray50", "gray70"))
# load data
robustdata <- base::readRDS(url("https://slcladal.github.io/data/mld.rda", "rb"))
# inspect data
robustdata %>%
as.data.frame() %>%
head(15) %>%
flextable() %>%
flextable::set_table_properties(width = .75, layout = "autofit") %>%
flextable::theme_zebra() %>%
flextable::fontsize(size = 12) %>%
flextable::fontsize(size = 12, part = "header") %>%
flextable::align_text_col(align = "center") %>%
flextable::set_caption(caption = "First 15 rows of the robustdata.") %>%
flextable::border_outer()
# create model
slm <- lm(money ~ status + attraction, data = robustdata)
# inspect model
summary(slm)
# generate plots
autoplot(slm) +
theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank())
robustdata[c(52, 64, 83), ]
CooksDistance <- cooks.distance(slm)
StandardizedResiduals <- stdres(slm)
a <- cbind(robustdata, CooksDistance, StandardizedResiduals)
a[CooksDistance > 4 / 100, ]
AbsoluteStandardizedResiduals <- abs(StandardizedResiduals)
a <- cbind(robustdata, CooksDistance, StandardizedResiduals, AbsoluteStandardizedResiduals)
asorted <- a[order(-AbsoluteStandardizedResiduals), ]
asorted[1:10, ]
# create robust regression model
rmodel <- robustbase::lmrob(money ~ status + attraction, data = robustdata)
# inspect model
summary(rmodel)
hweights <- data.frame(status = robustdata$status, resid = rmodel$resid, weight = rmodel$rweights)
hweights2 <- hweights[order(rmodel$rweights), ]
hweights2[1:15, ]
Height <- c(169, 171, 164, 160, 158, 173, 166, 161, 180, 187, 170, 177, 163, 161, 157)
Weight <- c(68, 67, 65, 66, 64, 80, 75, 70, 85, 92, 86, 87, 85, 82, 80)
Group <- c("a", "a", "a", "a", "a", "b", "b", "b", "b", "b", "c", "c", "c", "c", "c")
# create data sets
tb <- data.frame(Height, Weight, Group)
m1 <- lm(Weight ~ Height + Group, data = tb)
m2 <- lmer(Weight ~ Height + (1 | Group), data = tb)
tb <- tb %>%
dplyr::mutate(
PWeight = predict(m1, tb),
PWeight_lme = predict(m2, tb)
)
# plot
p1 <- ggplot(tb, aes(Height, Weight)) +
geom_point(size = 2)
p2 <- ggplot(tb, aes(Height, Weight)) +
geom_abline(
intercept = summary(m2)$coefficients[1], slope = summary(m2)$coefficients[2],
color = "orange", size = .75
) +
geom_point(size = 2) +
ggtitle("Fixed-effects model \n(with fixed intercept)")
p3 <- ggplot(tb, aes(Height, Weight)) +
geom_point(size = 2, aes(shape = Group, color = Group)) +
geom_abline(
intercept = fixef(m2)[1], slope = fixef(m2)[2],
color = "orange", size = .75
) +
geom_smooth(method = "lm", se = F, aes(x = Height, y = PWeight, color = Group), size = .5) +
theme(legend.position = "none") +
ggtitle("Mixed-effects model \n (with random intercepts)")
p4 <- ggplot(tb, aes(Height, Weight)) +
geom_smooth(se = F, method = "lm", size = .5, aes(shape = Group, color = Group)) +
geom_abline(
intercept = fixef(m2)[1], slope = fixef(m2)[2],
color = "orange", size = .75
) +
geom_point(size = 2, aes(shape = Group, color = Group)) +
theme(legend.position = "none") +
ggtitle("Mixed-effects model \n(with random intercepts + \nrandom slops)")
# show plot
ggpubr::ggarrange(p2, p3, p4, ncol = 3)
# load data
lmmdata <- base::readRDS(url("https://slcladal.github.io/data/lmd.rda", "rb")) %>%
# convert date into a numeric variable
dplyr::mutate(Date = as.numeric(Date))
# inspect data
lmmdata %>%
as.data.frame() %>%
head(15) %>%
flextable() %>%
flextable::set_table_properties(width = .75, layout = "autofit") %>%
flextable::theme_zebra() %>%
flextable::fontsize(size = 12) %>%
flextable::fontsize(size = 12, part = "header") %>%
flextable::align_text_col(align = "center") %>%
flextable::set_caption(caption = "First 15 rows of the lmmdata.") %>%
flextable::border_outer()
p1 <- ggplot(lmmdata, aes(x = Date, y = Prepositions)) +
geom_point() +
geom_smooth(method = "lm", se = F, color = "red", linetype = "dashed") +
theme_bw() +
labs(y = "Frequency\n(Prepositions)")
p2 <- ggplot(lmmdata, aes(x = reorder(Genre, -Prepositions), y = Prepositions)) +
geom_boxplot() +
theme_bw() +
theme(axis.text.x = element_text(angle = 90)) +
labs(x = "Genre", y = "Frequency\n(Prepositions)")
p3 <- ggplot(lmmdata, aes(Prepositions)) +
geom_histogram() +
theme_bw() +
labs(y = "Count", x = "Frequency (Prepositions)")
grid.arrange(grobs = list(p1, p2, p3), widths = c(1, 1), layout_matrix = rbind(c(1, 1), c(2, 3)))
p4 <- ggplot(lmmdata, aes(Date, Prepositions)) +
geom_point() +
labs(x = "Year", y = "Prepositions per 1,000 words") +
geom_smooth(method = "lm") +
theme_bw()
p5 <- ggplot(lmmdata, aes(Region, Prepositions)) +
geom_boxplot() +
labs(x = "Region", y = "Prepositions per 1,000 words") +
geom_smooth(method = "lm") +
theme_bw()
grid.arrange(p4, p5, nrow = 1)
ggplot(lmmdata, aes(Date, Prepositions)) +
geom_point() +
facet_wrap(~Genre, nrow = 4) +
geom_smooth(method = "lm") +
theme_bw() +
labs(x = "Date of composition", y = "Prepositions per 1,000 words") +
coord_cartesian(ylim = c(0, 220))
lmmdata$DateUnscaled <- lmmdata$Date
lmmdata$Date <- scale(lmmdata$Date, scale = F)
# inspect data
lmmdata %>%
as.data.frame() %>%
head(15) %>%
flextable() %>%
flextable::set_table_properties(width = .75, layout = "autofit") %>%
flextable::theme_zebra() %>%
flextable::fontsize(size = 12) %>%
flextable::fontsize(size = 12, part = "header") %>%
flextable::align_text_col(align = "center") %>%
flextable::set_caption(caption = "First 15 rows of the lmmdata.") %>%
flextable::border_outer()
# generate models
m0.glm <- glm(Prepositions ~ 1, family = gaussian, data = lmmdata)
m0.lmer <- lmer(Prepositions ~ 1 + (1 | Genre), REML = T, data = lmmdata)
AIC(logLik(m0.glm))
AIC(logLik(m0.lmer))
# generate models with 2 different random effect structures
ma.lmer <- lmer(Prepositions ~ Date + (1 | Genre), REML = T, data = lmmdata)
mb.lmer <- lmer(Prepositions ~ Date + (1 + Date | Genre), REML = T, data = lmmdata)
# compare models
anova(ma.lmer, mb.lmer, test = "Chisq", refit = F)
m1.lmer <- lmer(Prepositions ~ (1 | Genre) + Date, REML = T, data = lmmdata)
anova(m1.lmer, m0.lmer, test = "Chi")
mc1 <- anova(m1.lmer, m0.lmer, test = "Chi")
# generate model
m2.lmer <- update(m1.lmer, . ~ . + Region)
# test vifs
car::vif(m2.lmer)
# compare models
anova(m2.lmer, m1.lmer, test = "Chi")
# generate model
m3.lmer <- update(m1.lmer, . ~ . + Region * Date)
# extract vifs
car::vif(m3.lmer)
# compare models
anova(m3.lmer, m1.lmer, test = "Chi")
# inspect results
summary(m1.lmer)
plot(m1.lmer, Genre ~ resid(.), abline = 0) # generate diagnostic plots
plot(m1.lmer, resid(., type = "pearson") ~ fitted(.) | Genre,
id = 0.05,
adj = -0.3, pch = 20, col = "gray40"
)
# check homogeneity
leveneTest(lmmdata$Prepositions, lmmdata$Genre, center = mean)
# generate models
m4.lme <- lme(Prepositions ~ Date, random = ~ 1 | Genre, data = lmmdata, method = "ML")
m5.lme <- update(m4.lme, weights = varIdent(form = ~ 1 | Genre))
# compare models
anova(m5.lme, m4.lme)
# inspect results
summary(m5.lme)
anova(m5.lme)
# generate base-line model
m0.lme <- lme(Prepositions ~ 1, random = ~ 1 | Genre, data = lmmdata, method = "ML", weights = varIdent(form = ~ 1 | Genre))
anova(m0.lme, m5.lme) # test if date is significant
# extract estimates and sd for fixed and random effects
intervals(m5.lme, which = "fixed")
sjPlot::tab_model(m5.lme)
# extract R2s
r.squaredGLMM(m1.lmer)
sjPlot::plot_model(m5.lme, type = "pred", terms = c("Date")) +
# show uncentered date rather than centered date
scale_x_continuous(
name = "Date",
breaks = seq(-500, 300, 100),
labels = seq(1150, 1950, 100)
)
# extract predicted values
lmmdata$Predicted <- predict(m5.lme, lmmdata)
# plot predicted values
ggplot(lmmdata, aes(DateUnscaled, Predicted)) +
facet_wrap(~Genre) +
geom_point(aes(x = DateUnscaled, y = Prepositions), color = "gray80", size = .5) +
geom_smooth(aes(y = Predicted),
color = "gray20", linetype = "solid",
se = T, method = "lm"
) +
guides(color = guide_legend(override.aes = list(fill = NA))) +
theme_set(theme_bw(base_size = 10)) +
theme(
legend.position = "top", legend.title = element_blank(),
panel.grid.major = element_blank(),
panel.grid.minor = element_blank()
) +
xlab("Date of composition")
# start plotting
par(mfrow = c(2, 2)) # display plots in 2 rows and 2 columns
plot(m5.lme, pch = 20, col = "black", lty = "dotted")
par(mfrow = c(1, 1))
# fitted values by Genre
plot(m5.lme,
form = resid(., type = "p") ~ fitted(.) | Genre, abline = 0,
cex = .5, pch = 20, col = "black"
)
# residuals of fitted values against observed
qqnorm(m5.lme, pch = 20, col = "black")
# residuals by genre
qqnorm(m5.lme, ~ resid(.) | Genre, pch = 20, col = "black")
# observed responses versus the within-group fitted values
plot(m5.lme, Prepositions ~ fitted(.),
id = 0.05, adj = -0.3,
xlim = c(80, 220), cex = .8, pch = 20, col = "blue"
)
summary(m5.lme)
sjPlot::tab_model(m5.lme)
r.squaredGLMM(m5.lme)
report::report(m5.lme)
