{
  "hash": "0ee5cd179a1fd086cad068291bef1d2b",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Topic Modeling with R\"\nauthor: \"Martin Schweinberger\"\n---\n\n\n\n![](/images/uq1.jpg){ width=100% }\n\n# Introduction{-}\n\nThis tutorial introduces topic modeling using R. \n\n![](/images/gy_chili.png){ width=15% style=\"float:right; padding:10px\" }\n\nThis tutorial is aimed at beginners and intermediate users of R with the aim of showcasing how to perform basic topic modeling on textual data using R and how to visualize the results of such a model. The aim is not to provide a fully-fledged analysis but rather to show and exemplify selected useful methods associated with topic modeling. \n\n\n\n\n<div class=\"warning\" style='padding:0.1em; background-color:rgba(215,209,204,.3); color:#51247a'>\n<span>\n<p style='margin-top:1em; text-align:center'>\nTo be able to follow this tutorial, we suggest you check out and familiarize yourself with the content of the following **R Basics** tutorials:<br>\n</p>\n<p style='margin-top:1em; text-align:left'>\n<ul>\n  <li>[Getting started with R](https://ladal.edu.au/intror.html) </li>\n  <li>[Loading, saving, and generating data in R](https://ladal.edu.au/load.html) </li>\n  <li>[String Processing in R](https://ladal.edu.au/string.html) </li>\n  <li>[Regular Expressions in R](https://ladal.edu.au/regex.html) </li>\n</ul>\n</p>\n<p style='margin-top:1em; text-align:center'>\nClick [**here**](https://ladal.edu.au/content/topic.Rmd)^[If you want to render the R Notebook on your machine, i.e. knitting the document to html or a pdf, you need to make sure that you have R and RStudio installed and you also need to download the [**bibliography file**](https://slcladal.github.io/content/bibliography.bib) and store it in the same folder where you store the Rmd file.] to download the **entire R Notebook** for this tutorial.<br><br>\n[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/SLCLADAL/interactive-notebooks-environment/main?urlpath=git-pull%3Frepo%3Dhttps%253A%252F%252Fgithub.com%252FSLCLADAL%252Finteractive-notebooks%26urlpath%3Dlab%252Ftree%252Finteractive-notebooks%252Fnotebooks%252Ftm_cb.ipynb%26branch%3Dmain)<br>\nClick [**here**](https://mybinder.org/v2/gh/SLCLADAL/interactive-notebooks-environment/main?urlpath=git-pull%3Frepo%3Dhttps%253A%252F%252Fgithub.com%252FSLCLADAL%252Finteractive-notebooks%26urlpath%3Dlab%252Ftree%252Finteractive-notebooks%252Fnotebooks%252Ftm_cb.ipynb%26branch%3Dmain)  to open a Jupyter notebook that allows you to follow this tutorial interactively. This means that you can execute, change, and edit the code used in this tutorial to help you better understand how the code shown here works (make sure you run all code chunks in the order in which they appear to avoid running into errors).  </p> <br>\n</p>\n<p style='margin-left:1em;'>\n</p></span>\n</div>\n\n<br>\n\n\n<div class=\"warning\" style='padding:0.1em; background-color:#51247a; color:#f2f2f2'>\n<span>\n<p style='margin-top:1em; text-align:center'>\n**TOPIC MODEL TOOL** \n</p>\n<p style='margin-top:1em; text-align:center'>\nClick on this [![Binder](https://mybinder.org/badge_logo.svg)](https://binderhub.atap-binder.cloud.edu.au/v2/gh/SLCLADAL/interactive-notebooks-environment/main?urlpath=git-pull%3Frepo%3Dhttps%253A%252F%252Fgithub.com%252FSLCLADAL%252Finteractive-notebooks%26urlpath%3Dlab%252Ftree%252Finteractive-notebooks%252Fnotebooks%252Ftopictool.ipynb%26branch%3Dmain) badge to open an notebook-based tool <br>that allows you to upload your own text(s), perform topic modelling on them, and download the results. </p><br>\n<p style='margin-left:1em;'>\n</p></span>\n</div>\n\n<br>\n\nThis tutorial builds heavily on and uses materials from [@silge2017text, chapter 6] (see [here](https://www.tidytextmining.com/topicmodeling)) and  [this tutorial](https://tm4ss.github.io/docs/Tutorial_6_Topic_Models.html) on topic modelling using R by Andreas Niekler and Gregor Wiedemann [see @WN17]. [The tutorial](https://tm4ss.github.io/docs/index.html) by Andreas Niekler and Gregor Wiedemann is more thorough, goes into more detail than this tutorial, and covers many more very useful text mining methods. \n\n<div class=\"warning\" style='padding:0.1em; background-color:#f2f2f2; color:#51247a'>\n<span>\n<p style='margin-top:1em; text-align:center'>\n**Topic models aim to find topics (which are operationalized as bundles of correlating terms) in documents to see what the texts are about.**</p>\n<p style='margin-left:1em;'>\n</p></span>\n</div>\n\n<br>\n\nTopic models refers to a suit of methods employed to uncover latent structures within a corpus of text. These models operate on the premise of identifying abstract *topics* that recur across documents. In essence, topic models sift through the textual data to discern recurring patterns of word co-occurrence, revealing underlying semantic themes [@busso2022operation; @blei2003latent]. This technique is particularly prevalent in text mining, where it serves to unveil hidden semantic structures in large volumes of textual data.\n\nConceptually, topics can be understood as clusters of co-occurring terms, indicative of shared semantic domains within the text. The underlying assumption is that if a document pertains to a specific topic, words related to that topic will exhibit higher frequency compared to documents addressing other subjects. For example, in documents discussing dogs, terms like *dog* and *bone* are likely to feature prominently, while in documents focusing on cats, *cat* and *meow* would be more prevalent. Meanwhile, ubiquitous terms such as *the* and *is* are expected to occur with similar frequency across diverse topics, serving as noise rather than indicative signals of topic specificity.\n\nVarious methods exist for determining topics within topic models. For instance, @gerlach2018network and @hyland2021multilayer advocate for an approach grounded in stochastic block models. However, most applications of topic models use Latent Dirichlet Allocation (LDA) [@blei2003latent] or Structural Topic Modeling  [@roberts2016navigating].\n\nLDA, in particular, emerges as a widely embraced technique for fitting topic models. It operates by treating each document as a blend of topics and each topic as a blend of words. Consequently, documents can exhibit content overlaps, akin to the fluidity observed in natural language usage, rather than being strictly segregated into distinct groups.\n\n@gillings2022interpretation state that topic modelling is based on the following key assumptions:\n\n* The corpus comprises a substantial number of documents.  \n* A topic is delineated as a set of words with varying probabilities of occurrence across the documents.  \n* Each document exhibits diverse degrees of association with multiple topics.  \n* The collection is structured by underlying topics, which are finite in number, organizing the corpus.  \n\nGiven the availability of vast amounts of textual data, topic models can help to organize and offer insights and assist in understanding large collections of unstructured text and they are widely used in natural language processing and computational text analytics. However, the use of topic modelling in discourse studies has received criticism [@brookes2019utility] due to the following issues: \n\n1. **Thematic Coherence**: While topic modeling can group texts into *topics*, the degree of thematic coherence varies. Some topics may be thematically coherent, but others may lack cohesion or accuracy in capturing the underlying themes present in the texts.\n\n2. **Nuanced Perspective**: Compared to more traditional approaches to discourse analysis, topic modeling often provides a less nuanced perspective on the data. The automatically generated topics may overlook subtle nuances and intricacies present in the texts, leading to a less accurate representation of the discourse.\n\n3. **Distance from Reality**: @brookes2019utility suggest that the insights derived from topic modeling may not fully capture the \"reality\" of the texts. The topics generated by the model may not accurately reflect the complex nature of the discourse, leading to potential misinterpretations or oversimplifications of the data.\n\n4. **Utility for Discourse Analysts**: While topic modeling may offer a method for organizing and studying sizable data sets, @brookes2019utility questions the utility for discourse analysts and suggests that traditional discourse analysis methods consistently provide a more nuanced and accurate perspective on the data compared to topic modeling approaches.\n\nThis criticism is certainly valid if topic modeling is solely reliant on a purely data-driven approach without human intervention. In this tutorial, we will demonstrate how to combine data-driven topic modeling with human-supervised seeded methods to arrive at more reliable and accurate topics.\n\n**Preparation and session set up**\n\nThis tutorial is conducted within the R environment. If you're new to R or haven't installed it yet, you can find an introduction to R and further instructions on how to use it [here](https://ladal.edu.au/intror.html). To ensure smooth execution of the scripts provided in this tutorial, it's necessary to install specific packages from the R library. Before proceeding to the code examples, please ensure you've installed these packages by running the code provided below. If you've already installed the required packages, feel free to skip ahead and disregard this section. To install the necessary packages, simply execute the following code. Please note that installation may take some time (usually between 1 and 5 minutes), so there's no need to be concerned if it takes a while.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# install packages\ninstall.packages(\"dplyr\")\ninstall.packages(\"flextable\")\ninstall.packages(\"ggplot2\")\ninstall.packages(\"lda\")\ninstall.packages(\"ldatuning\")\ninstall.packages(\"quanteda\")\ninstall.packages(\"RColorBrewer\")\ninstall.packages(\"reshape2\")\ninstall.packages(\"slam\")\ninstall.packages(\"stringr\")\ninstall.packages(\"tidyr\")\ninstall.packages(\"tidytext\")\ninstall.packages(\"tm\")\ninstall.packages(\"topicmodels\")\ninstall.packages(\"wordcloud\")\n# install klippy for copy-to-clipboard button in code chunks\ninstall.packages(\"remotes\")\nremotes::install_github(\"rlesur/klippy\")\n```\n:::\n\n\n\nNext, we activate the packages. \n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# set options\noptions(stringsAsFactors = F) # no automatic data transformation\noptions(\"scipen\" = 100, \"digits\" = 4) # suppress math annotation\n# load packages\nlibrary(dplyr)\nlibrary(flextable)\nlibrary(ggplot2)\nlibrary(lda)\nlibrary(ldatuning)\nlibrary(quanteda)\nlibrary(RColorBrewer)\nlibrary(reshape2)\nlibrary(slam)\nlibrary(stringr)\nlibrary(tidyr)\nlibrary(tidytext)\nlibrary(tm)\nlibrary(topicmodels)\nlibrary(wordcloud)\n# activate klippy for copy-to-clipboard button\nklippy::klippy()\n```\n\n::: {.cell-output-display}\n\n```{=html}\n<script>\n  addClassKlippyTo(\"pre.r, pre.markdown\");\n  addKlippy('left', 'top', 'auto', '1', 'Copy code', 'Copied!');\n</script>\n```\n\n:::\n:::\n\n\n\nOnce you have installed R and RStudio and once you have initiated the session by executing the code shown above, you are good to go.\n\n\n# Topic Modelling{-}\n\nIn this tutorial, we'll explore a two-step approach to topic modeling. Initially, we'll employ an unsupervised method to generate a preliminary topic model, uncovering inherent topics within the data. Subsequently, we'll introduce a human-supervised, seeded model, informed by the outcomes of the initial data-driven approach. Following this (recommended) procedure, we'll then delve into an alternative purely data-driven approach.\n\nOur tutorial begins by gathering the necessary corpus data. We'll be focusing on analyzing the *State of the Union Addresses* (SOTU) delivered by US presidents, with the aim of understanding how the addressed topics have evolved over time. Given the length of these addresses (amounting to 231 in total), it's important to acknowledge that document length can influence topic modeling outcomes. In cases where texts are exceptionally short (like Twitter posts) or long (such as books), adjusting the document units for modeling purposes can be beneficial—either by combining or splitting them accordingly.\n\nTo tailor our approach to the SOTU speeches, we've chosen to model at the paragraph level instead of analyzing entire speeches at once. This allows for a more detailed analysis, potentially leading to clearer and more interpretable topics. We've provided a data set named `sotu_paragraphs.rda`, which contains the speeches segmented into paragraphs for easier analysis.\n\n\n## Human-in-the-loop Topic Modelling {-}\n\nIn this human-in-the-loop approach to topic modelling which mainly uses and combines the `quanteda` package [@benoit2018quanteda], the `topicmodels` package [@topicmodels2024package; @topicmodels2011pub], and the `seededlda` package [@seededlda2024]. Now that we have cleaned the data, we can perform the topic modelling. This consists of two steps:\n\n1. First, we perform an unsupervised LDA. We do this to check what topics are in our corpus. \n\n2. Then, we perform a supervised LDA (based on the results of the unsupervised LDA) to identify meaningful topics in our data. For the supervised LDA, we define so-called *seed terms* that help in generating coherent topics.\n\n### Loading and preparing data {-}\n\nWhen preparing the data for analysis, we employ several preprocessing steps to ensure its cleanliness and readiness for analysis. Initially, we load the data and then remove punctuation, symbols, and numerical characters. Additionally, we eliminate common stop words, such as *the* and *and*, which can introduce noise and hinder the topic modeling process. To standardize the text, we convert it to lowercase and, lastly, we apply stemming to reduce words to their base form.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# load data\ntxts <- base::readRDS(url(\"https://slcladal.github.io/data/sotu_paragraphs.rda\", \"rb\"))\ntxts$text %>%\n  # tokenise\n  quanteda::tokens(\n    remove_punct = TRUE, # remove punctuation\n    remove_symbols = TRUE, # remove symbols\n    remove_number = TRUE\n  ) %>% # remove numbers\n  # remove stop words\n  quanteda::tokens_select(pattern = stopwords(\"en\"), selection = \"remove\") %>%\n  # stemming\n  quanteda::tokens_wordstem() %>%\n  # convert to document-frequency matrix\n  quanteda::dfm(tolower = T) -> ctxts\n# add docvars\ndocvars(ctxts, \"president\") <- txts$president\ndocvars(ctxts, \"date\") <- txts$date\ndocvars(ctxts, \"speechid\") <- txts$speech_doc_id\ndocvars(ctxts, \"docid\") <- txts$doc_id\n# clean data\nctxts <- dfm_subset(ctxts, ntoken(ctxts) > 0)\n# inspect data\nctxts[1:5, 1:5]\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nDocument-feature matrix of: 5 documents, 5 features (80.00% sparse) and 4 docvars.\n       features\ndocs    fellow-citizen senat hous repres embrac\n  text1              1     1    1      1      0\n  text2              0     0    0      0      1\n  text3              0     0    0      0      0\n  text4              0     0    0      0      0\n  text5              0     0    0      0      0\n```\n\n\n:::\n:::\n\n\n\n### Initial unsupervised topic model{-}\n\nNow that we have loaded and prepared the data for analysis, we will follow a two-step approach. \n\n1. First, we perform an unsupervised topic model using Latent Dirichlet Allocation (LDA) to identify the topics present in our data. This initial step helps us understand the broad themes and structure within the data set. \n\n2. Then, based on the results of the unsupervised topic model, we conduct a supervised topic model using LDA to refine and identify more meaningful topics in our data.\n\nThis combined approach allows us to leverage both data-driven insights and expert supervision to enhance the accuracy and interpretability of the topics.\n\nIn the initial  step that implements a unsupervised, data-driven topic model, we vary the number of topics the LDA algorithm looks for until we identify coherent topics in the data. We use the `LDA` function from the `topicmodels` package instead of the `textmodel_lda` function from the `seededlda` package because the former allows us to include a seed. Including a seed ensures that the results of this unsupervised topic model are reproducible, which is not the case if we do not seed the model, as each model will produce different results without setting a seed.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# generate model: change k to different numbers, e.g. 10 or 20 and look for consistencies in the keywords for the topics below.\ntopicmodels::LDA(ctxts, k = 15, control = list(seed = 1234)) -> ddlda\n```\n:::\n\n\n\nNow that we have generated an initial data-driven model, the next step is to inspect it to evaluate its performance and understand the topics it has identified. To do this, we need to examine the terms associated with each detected topic. By analyzing these terms, we can gain insights into the themes represented by each topic and assess the coherence and relevance of the model's output.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# define number of topics\nntopics <- 15\n# define number of terms\nnterms <- 10\n# generate table\ntidytext::tidy(ddlda, matrix = \"beta\") %>%\n  dplyr::group_by(topic) %>%\n  dplyr::slice_max(beta, n = nterms) %>%\n  dplyr::ungroup() %>%\n  dplyr::arrange(topic, -beta) %>%\n  dplyr::mutate(\n    term = paste(term, \" (\", round(beta, 3), \")\", sep = \"\"),\n    topic = paste(\"topic\", topic),\n    topic = factor(topic, levels = c(paste(\"topic\", 1:ntopics))),\n    top = rep(paste(\"top\", 1:nterms), nrow(.) / nterms),\n    top = factor(top, levels = c(paste(\"top\", 1:nterms)))\n  ) %>%\n  dplyr::select(-beta) %>%\n  tidyr::spread(topic, term) -> ddlda_top_terms\nddlda_top_terms\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 10 × 16\n   top    `topic 1`  `topic 2` `topic 3` `topic 4` `topic 5` `topic 6` `topic 7`\n   <fct>  <chr>      <chr>     <chr>     <chr>     <chr>     <chr>     <chr>    \n 1 top 1  state (0.… countri … state (0… govern (… state (0… state (0… state (0…\n 2 top 2  countri (… upon (0.… unite (0… will (0.… countri … will (0.… upon (0.…\n 3 top 3  will (0.0… present … congress… year (0.… will (0.… unite (0… will (0.…\n 4 top 4  congress … war (0.0… may (0.0… unite (0… congress… govern (… congress…\n 5 top 5  nation (0… can (0.0… treati (… law (0.0… public (… power (0… may (0.0…\n 6 top 6  can (0.00… unite (0… citizen … may (0.0… year (0.… law (0.0… govern (…\n 7 top 7  subject (… nation (… nation (… upon (0.… nation (… peopl (0… citizen …\n 8 top 8  govern (0… author (… great (0… act (0.0… can (0.0… last (0.… nation (…\n 9 top 9  land (0.0… may (0.0… territor… public (… law (0.0… duti (0.… import (…\n10 top 10 made (0.0… subject … made (0.… last (0.… import (… part (0.… great (0…\n# ℹ 8 more variables: `topic 8` <chr>, `topic 9` <chr>, `topic 10` <chr>,\n#   `topic 11` <chr>, `topic 12` <chr>, `topic 13` <chr>, `topic 14` <chr>,\n#   `topic 15` <chr>\n```\n\n\n:::\n:::\n\n\n\nIn a real analysis, we would re-run the unsupervised model multiple times, adjusting the number of topics that the Latent Dirichlet Allocation (LDA) algorithm \"looks for.\" For each iteration, we would inspect the key terms associated with the identified topics to check their thematic consistency. This evaluation helps us determine whether the results of the topic model make sense and accurately reflect the themes present in the data. By varying the number of topics and examining the corresponding key terms, we can identify the optimal number of topics that best represent the underlying themes in our data set. However, we will skip re-running the model here, as this is just a tutorial intended to showcase the process rather than a comprehensive analysis.\n\nTo obtain a comprehensive table of terms and their association strengths with topics (the beta values), follow the steps outlined below. This table can help verify if the data contains thematically distinct topics. Additionally, visualizations and statistical modeling can be employed to compare the distinctness of topics and determine the ideal number of topics. However, I strongly recommend not solely relying on statistical measures when identifying the optimal number of topics. In my experience, human intuition is still essential for evaluating topic coherence and consistency.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# extract topics\nddlda_topics <- tidy(ddlda, matrix = \"beta\")\n# inspect\nhead(ddlda_topics, 20)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 20 × 3\n   topic term                beta\n   <int> <chr>              <dbl>\n 1     1 fellow-citizen 0.000249 \n 2     2 fellow-citizen 0.000351 \n 3     3 fellow-citizen 0.000416 \n 4     4 fellow-citizen 0.0000333\n 5     5 fellow-citizen 0.0000797\n 6     6 fellow-citizen 0.000183 \n 7     7 fellow-citizen 0.000445 \n 8     8 fellow-citizen 0.000306 \n 9     9 fellow-citizen 0.000381 \n10    10 fellow-citizen 0.000332 \n11    11 fellow-citizen 0.000187 \n12    12 fellow-citizen 0.000147 \n13    13 fellow-citizen 0.000278 \n14    14 fellow-citizen 0.000336 \n15    15 fellow-citizen 0.000205 \n16     1 senat          0.000708 \n17     2 senat          0.000477 \n18     3 senat          0.00263  \n19     4 senat          0.00118  \n20     5 senat          0.000436 \n```\n\n\n:::\n:::\n\n\n\nThe purpose of this initial step, in which we generate data-driven unsupervised topic models, is to identify the number of coherent topics present in the data and to determine the key terms associated with these topics. These key terms will then be used as seed terms in the next step: the supervised, seeded topic model. This approach ensures that the supervised model is grounded in the actual thematic structure of the data set, enhancing the accuracy and relevance of the identified topics.\n\n### Supervised, seeded topic model{-}\n\nTo implement the supervised, seeded topic model, we start by creating a dictionary containing the seed terms we have identified in the first step.\n\nTo check terms (to see if ), you can use the following code chunk:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nddlda_topics %>%\n  select(term) %>%\n  unique() %>%\n  filter(str_detect(term, \"agri\"))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 3 × 1\n  term               \n  <chr>              \n1 agricultur         \n2 agriculturist      \n3 agricultural-colleg\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# semisupervised LDA\ndict <- dictionary(list(\n  military = c(\"armi\", \"war\", \"militari\", \"conflict\"),\n  liberty = c(\"freedom\", \"liberti\", \"free\"),\n  nation = c(\"nation\", \"countri\", \"citizen\"),\n  law = c(\"law\", \"court\", \"prison\"),\n  treaty = c(\"claim\", \"treati\", \"negoti\"),\n  indian = c(\"indian\", \"tribe\", \"territori\"),\n  labor = c(\"labor\", \"work\", \"condit\"),\n  money = c(\"bank\", \"silver\", \"gold\", \"currenc\", \"money\"),\n  finance = c(\"debt\", \"invest\", \"financ\"),\n  wealth = c(\"prosper\", \"peac\", \"wealth\"),\n  industry = c(\"produc\", \"industri\", \"manufactur\"),\n  navy = c(\"navi\", \"ship\", \"vessel\", \"naval\"),\n  consitution = c(\"constitut\", \"power\", \"state\"),\n  agriculture = c(\"agricultur\", \"grow\", \"land\"),\n  office = c(\"office\", \"serv\", \"duti\")\n))\ntmod_slda <- seededlda::textmodel_seededlda(ctxts,\n  dict,\n  residual = TRUE,\n  min_termfreq = 2\n)\n# inspect\nseededlda::terms(tmod_slda)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n      military   liberty   nation    law        treaty    indian     \n [1,] \"war\"      \"free\"    \"countri\" \"law\"      \"treati\"  \"territori\"\n [2,] \"militari\" \"peopl\"   \"nation\"  \"court\"    \"claim\"   \"indian\"   \n [3,] \"armi\"     \"can\"     \"citizen\" \"case\"     \"govern\"  \"tribe\"    \n [4,] \"forc\"     \"must\"    \"great\"   \"govern\"   \"negoti\"  \"mexico\"   \n [5,] \"offic\"    \"upon\"    \"us\"      \"person\"   \"unite\"   \"part\"     \n [6,] \"servic\"   \"liberti\" \"peopl\"   \"upon\"     \"minist\"  \"texa\"     \n [7,] \"men\"      \"one\"     \"will\"    \"properti\" \"convent\" \"new\"      \n [8,] \"command\"  \"govern\"  \"everi\"   \"author\"   \"britain\" \"made\"     \n [9,] \"conflict\" \"will\"    \"honor\"   \"justic\"   \"british\" \"boundari\" \n[10,] \"arm\"      \"polit\"   \"can\"     \"made\"     \"two\"     \"line\"     \n      labor       money      finance      wealth       industry     navy       \n [1,] \"condit\"    \"bank\"     \"year\"       \"peac\"       \"produc\"     \"vessel\"   \n [2,] \"work\"      \"money\"    \"debt\"       \"govern\"     \"industri\"   \"navi\"     \n [3,] \"labor\"     \"gold\"     \"amount\"     \"prosper\"    \"manufactur\" \"ship\"     \n [4,] \"report\"    \"currenc\"  \"expenditur\" \"relat\"      \"product\"    \"naval\"    \n [5,] \"depart\"    \"silver\"   \"treasuri\"   \"interest\"   \"import\"     \"port\"     \n [6,] \"congress\"  \"govern\"   \"will\"       \"continu\"    \"foreign\"    \"commerc\"  \n [7,] \"attent\"    \"public\"   \"fiscal\"     \"friend\"     \"increas\"    \"construct\"\n [8,] \"secretari\" \"treasuri\" \"last\"       \"will\"       \"trade\"      \"coast\"    \n [9,] \"servic\"    \"note\"     \"estim\"      \"intercours\" \"revenu\"     \"sea\"      \n[10,] \"recommend\" \"issu\"     \"revenu\"     \"spain\"      \"tariff\"     \"new\"      \n      consitution agriculture  office     other     \n [1,] \"state\"     \"land\"       \"duti\"     \"congress\"\n [2,] \"power\"     \"agricultur\" \"will\"     \"act\"     \n [3,] \"constitut\" \"public\"     \"may\"      \"last\"    \n [4,] \"unite\"     \"grow\"       \"subject\"  \"session\" \n [5,] \"govern\"    \"year\"       \"congress\" \"repres\"  \n [6,] \"right\"     \"larg\"       \"consider\" \"presid\"  \n [7,] \"union\"     \"improv\"     \"can\"      \"hous\"    \n [8,] \"shall\"     \"new\"        \"shall\"    \"senat\"   \n [9,] \"author\"    \"reserv\"     \"public\"   \"provis\"  \n[10,] \"exercis\"   \"acr\"        \"object\"   \"day\"     \n```\n\n\n:::\n:::\n\n\n\nNow, we extract files and create a data frame of topics and documents. This shows what topic is dominant in which file in tabular form.  \n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# generate data frame\ndata.frame(tmod_slda$data$date, tmod_slda$data$president, seededlda::topics(tmod_slda)) %>%\n  dplyr::rename(\n    Date = 1,\n    President = 2,\n    Topic = 3\n  ) %>%\n  dplyr::mutate(\n    Date = stringr::str_remove_all(Date, \"-.*\"),\n    Date = stringr::str_replace_all(Date, \".$\", \"0\")\n  ) %>%\n  dplyr::mutate_if(is.character, factor) -> topic_df\n# inspect\nhead(topic_df)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n      Date         President    Topic\ntext1 1790 George Washington    other\ntext2 1790 George Washington   nation\ntext3 1790 George Washington   nation\ntext4 1790 George Washington    labor\ntext5 1790 George Washington military\ntext6 1790 George Washington   office\n```\n\n\n:::\n:::\n\n\n\nUsing the table (or data frame) we have just created, we can visualize the use of topics over time.\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntopic_df %>%\n  dplyr::group_by(Date, Topic) %>%\n  dplyr::summarise(freq = n()) %>%\n  ggplot(aes(x = Date, y = freq, fill = Topic)) +\n  geom_bar(stat = \"identity\", position = \"fill\", color = \"black\") +\n  theme_bw() +\n  labs(x = \"Decade\") +\n  scale_fill_manual(values = rev(colorRampPalette(brewer.pal(8, \"RdBu\"))(ntopics + 1))) +\n  scale_y_continuous(name = \"Percent of paragraphs\", labels = seq(0, 100, 25))\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n`summarise()` has grouped output by 'Date'. You can override using the\n`.groups` argument.\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](topic_files/figure-html/vis-1.png){width=672}\n:::\n:::\n\n\n\nThe figure illustrates the relative frequency of topics over time in the State of the Union (SOTU) texts. Notably, paragraphs discussing the topic of \"office,\" characterized by key terms such as *office*, *serv*, and *duti*, have become less prominent over time. This trend suggests a decreasing emphasis on this particular theme, as evidenced by the diminishing number of paragraphs dedicated to it.\n\n## Data-driven Topic Modelling {-}\n\nIn this part of the tutorial, we show an alternative approaches for performing data-driven topic modelling using LDA. \n\n### Loading and preparing data {-}\n\nWhen readying the data for analysis, we follow consistent pre-processing steps, employing the `tm` package [@tm2024package; @tm2008pub] for efficient data preparation and cleaning. First, we load the data and convert it into a corpus object. Next, we convert the text to lowercase, eliminating superfluous white spaces, and removing stop words. Subsequently, we proceed to strip the data of punctuation, symbols, and numerical characters. Finally, we apply stemming to standardize words to their base form, ensuring uniformity throughout the data set.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# load data\ntextdata <- base::readRDS(url(\"https://slcladal.github.io/data/sotu_paragraphs.rda\", \"rb\"))\n# create corpus object\ntm::Corpus(DataframeSource(textdata)) %>%\n  # convert to lower case\n  tm::tm_map(content_transformer(tolower)) %>%\n  # remove superfluous white spaces\n  tm::tm_map(stripWhitespace) %>%\n  # remove stop words\n  tm::tm_map(removeWords, quanteda::stopwords()) %>%\n  # remove punctuation\n  tm::tm_map(removePunctuation, preserve_intra_word_dashes = TRUE) %>%\n  # remove numbers\n  tm::tm_map(removeNumbers) %>%\n  # stemming\n  tm::tm_map(stemDocument, language = \"en\") -> textcorpus\n# inspect data\nstr(textcorpus)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nClasses 'SimpleCorpus', 'Corpus'  hidden list of 3\n $ content: Named chr [1:8833] \"fellow-citizen senat hous repres\" \"embrac great satisfact opportun now present congratul present favor prospect public affair recent access import\"| __truncated__ \"resum consult general good can deriv encourag reflect measur last session satisfactori constitu novelti difficu\"| __truncated__ \"among mani interest object engag attent provid common defens merit particular regard prepar war one effectu mean preserv peac\" ...\n  ..- attr(*, \"names\")= chr [1:8833] \"1\" \"2\" \"3\" \"4\" ...\n $ meta   :List of 1\n  ..$ language: chr \"en\"\n  ..- attr(*, \"class\")= chr \"CorpusMeta\"\n $ dmeta  :'data.frame':\t8833 obs. of  4 variables:\n  ..$ speech_doc_id: int [1:8833] 1 1 1 1 1 1 1 1 1 1 ...\n  ..$ speech_type  : Factor w/ 1 level \"State of the Union Address\": 1 1 1 1 1 1 1 1 1 1 ...\n  ..$ president    : Factor w/ 23 levels \"Abraham Lincoln\",..: 7 7 7 7 7 7 7 7 7 7 ...\n  ..$ date         : chr [1:8833] \"1790-01-08\" \"1790-01-08\" \"1790-01-08\" \"1790-01-08\" ...\n```\n\n\n:::\n:::\n\n\n\n### Model calculation{-}\n\nHere's the improved and expanded version of the paragraph:\n\nAfter preprocessing, we have a clean corpus object called `textcorpus`, which we use to calculate the unsupervised Latent Dirichlet Allocation (LDA) topic model [@blei2003lda]. To perform this calculation, we first create a Document-Term Matrix (DTM) from the `textcorpus`. In this step, we ensure that only terms with a certain minimum frequency in the corpus are included (we set the minimum frequency to 5). This selection process not only speeds up the model calculation but also helps improve the model's accuracy by focusing on more relevant and frequently occurring terms. By filtering out less common terms, we reduce noise and enhance the coherence of the topics identified by the LDA model.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# compute document term matrix with terms >= minimumFrequency\nminimumFrequency <- 5\nDTM <- tm::DocumentTermMatrix(textcorpus,\n  control = list(bounds = list(global = c(minimumFrequency, Inf)))\n)\n# inspect the number of documents and terms in the DTM\ndim(DTM)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 8833 4472\n```\n\n\n:::\n:::\n\n\n\nDue to vocabulary pruning, some rows in our Document-Term Matrix (DTM) may end up being empty. Latent Dirichlet Allocation (LDA) cannot handle empty rows, so we must remove these documents from both the DTM and the corresponding metadata. This step ensures that the topic modeling process runs smoothly without encountering errors caused by empty documents. Additionally, removing these empty rows helps maintain the integrity of our analysis by focusing only on documents that contain meaningful content.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsel_idx <- slam::row_sums(DTM) > 0\nDTM <- DTM[sel_idx, ]\ntextdata <- textdata[sel_idx, ]\n# inspect the number of documents and terms in the DTM\ndim(DTM)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 8811 4472\n```\n\n\n:::\n:::\n\n\n\nThe output shows that we have removed 22 documents (8833 - 8811) from the DTM.\n\nAs an unsupervised machine learning method, topic models are well-suited for exploring data. The primary goal of calculating topic models is to determine the proportionate composition of a fixed number of topics within the documents of a collection. Experimenting with different parameters is essential to identify the most suitable settings for your analysis needs.\n\nFor parameterized models such as Latent Dirichlet Allocation (LDA), the number of topics `K` is the most critical parameter to define in advance. Selecting the optimal `K` depends on various factors. If `K` is too small, the collection is divided into a few very general semantic contexts. Conversely, if `K` is too large, the collection is divided into too many topics, leading to overlaps and some topics being barely interpretable. Finding the right balance is key to achieving meaningful and coherent topics in your analysis.\n\nAn alternative to deciding on a set number of topics is to extract parameters form a models using a rage of number of topics. This approach can be useful when the number of topics is not theoretically motivated or based on closer, qualitative inspection of the data. In the example below, the determination of the optimal number of topics follows @murzintcev2020idealtopics, but we only use two metrics (`CaoJuan2009` and `Deveaud2014`) - it is highly recommendable to inspect the results of the four metrics available for the `FindTopicsNumber` function  which are `Griffiths2004` [see @griffiths2004integrating], `CaoJuan2009` [see @cao2009density], `Arun2010` [see @arun2010finding], and `Deveaud2014` [see @deveaud2014accurate]. \n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# create models with different number of topics\nresult <- ldatuning::FindTopicsNumber(\n  DTM,\n  topics = seq(from = 2, to = 20, by = 1),\n  metrics = c(\"CaoJuan2009\", \"Deveaud2014\"),\n  method = \"Gibbs\",\n  control = list(seed = 77),\n  verbose = TRUE\n)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nfit models... done.\ncalculate metrics:\n  CaoJuan2009... done.\n  Deveaud2014... done.\n```\n\n\n:::\n:::\n\n\n\n\nWe can now plot the results. In this case, we have only use two methods `CaoJuan2009` and `Griffith2004`. The best number of topics shows low values for `CaoJuan2009` and high values for `Griffith2004` (optimally, several methods should converge and show peaks and dips respectively for a certain number of topics).\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nFindTopicsNumber_plot(result)\n```\n\n::: {.cell-output-display}\n![](topic_files/figure-html/tm3c-1.png){width=672}\n:::\n:::\n\n\n\n\nFor our first analysis, however, we choose a thematic \"resolution\" of `K = 20` topics. In contrast to a resolution of 100 or more, this number of topics can be evaluated qualitatively very easy.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# number of topics\nK <- 20\n# set random number generator seed\nset.seed(9161)\n# compute the LDA model, inference via 1000 iterations of Gibbs sampling\ntopicModel <- topicmodels::LDA(DTM, K, method = \"Gibbs\", control = list(iter = 500, verbose = 25))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nK = 20; V = 4472; M = 8811\nSampling 500 iterations!\nIteration 25 ...\nIteration 50 ...\nIteration 75 ...\nIteration 100 ...\nIteration 125 ...\nIteration 150 ...\nIteration 175 ...\nIteration 200 ...\nIteration 225 ...\nIteration 250 ...\nIteration 275 ...\nIteration 300 ...\nIteration 325 ...\nIteration 350 ...\nIteration 375 ...\nIteration 400 ...\nIteration 425 ...\nIteration 450 ...\nIteration 475 ...\nIteration 500 ...\nGibbs sampling completed!\n```\n\n\n:::\n\n```{.r .cell-code}\n# save results\ntmResult <- posterior(topicModel)\n# save theta values\ntheta <- tmResult$topics\n# save beta values\nbeta <- tmResult$terms\n# reset topic names\ntopicNames <- apply(terms(topicModel, 5), 2, paste, collapse = \" \")\n```\n:::\n\n\n\nDepending on the size of the vocabulary, the collection size and the number K, the inference of topic models can take a very long time. This calculation may take several minutes. If it takes too long, reduce the vocabulary in the DTM by increasing the minimum frequency in the previous step.\n\n\nLet's take a look at the 10 most likely terms within the term probabilities `beta` of the inferred topics.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# create a data frame from the topic model data\ntidytext::tidy(topicModel, matrix = \"beta\") %>%\n  # ensure topics are factors with specific levels\n  dplyr::mutate(\n    topic = paste0(\"topic\", as.character(topic)),\n    topic = factor(topic, levels = paste0(\"topic\", 1:20))\n  ) %>%\n  # group the data by topic\n  dplyr::group_by(topic) %>%\n  # arrange terms within each topic by beta value (ascending)\n  dplyr::arrange(topic, -beta) %>%\n  # select the top 10 terms with the highest beta values for each topic\n  dplyr::top_n(10) %>%\n  # add beta to term\n  dplyr::mutate(term = paste0(term, \" (\", round(beta, 3), \")\")) %>%\n  # remove the beta column as it is now part of the term string\n  dplyr::select(-beta) %>%\n  # ungroup the data frame\n  dplyr::ungroup() %>%\n  # create an id column for each term's position within the topic\n  dplyr::mutate(id = rep(1:10, 20)) %>%\n  # pivot the data to a wider format with topics as columns\n  tidyr::pivot_wider(names_from = topic, values_from = term) -> topterms\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nSelecting by beta\n```\n\n\n:::\n\n```{.r .cell-code}\n# inspect\ntopterms\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 10 × 21\n      id topic1  topic2 topic3 topic4 topic5 topic6 topic7 topic8 topic9 topic10\n   <int> <chr>   <chr>  <chr>  <chr>  <chr>  <chr>  <chr>  <chr>  <chr>  <chr>  \n 1     1 war (0… natio… gover… state… act (… may (… congr… new (… state… year (…\n 2     2 forc (… count… power… const… congr… upon … subje… great… terri… amount…\n 3     3 milita… peopl… natio… power… last … duti … recom… line … india… expend…\n 4     4 navi (… everi… indep… repre… made … shall… consi… const… mexic… increa…\n 5     5 armi (… prosp… princ… union… sessi… law (… atten… pacif… unit … treasu…\n 6     6 men (0… great… right… gover… autho… time … legis… estab… part … end (0…\n 7     7 offic … insti… polic… peopl… provi… requi… impor… compl… tribe… estim …\n 8     8 comman… happi… war (… hous … day (… prope… upon … coast… withi… revenu…\n 9     9 naval … honor… maint… exerc… first… neces… sugge… commu… exten… fiscal…\n10    10 servic… gener… inter… gener… effec… execu… prese… impor… texa … sum (0…\n# ℹ 10 more variables: topic11 <chr>, topic12 <chr>, topic13 <chr>,\n#   topic14 <chr>, topic15 <chr>, topic16 <chr>, topic17 <chr>, topic18 <chr>,\n#   topic19 <chr>, topic20 <chr>\n```\n\n\n:::\n:::\n\n\n\nFor the next steps, we want to give the topics more descriptive names than just numbers. Therefore, we simply concatenate the five most likely terms of each topic to a string that represents a pseudo-name for each topic. \n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntopicNames <- apply(terms(topicModel, 5), 2, paste, collapse = \" \")\n# inspect first 3 topic names\ntopicNames[1:3]\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                                Topic 1                                 Topic 2 \n          \"war forc militari navi armi\"    \"nation countri peopl everi prosper\" \n                                Topic 3 \n\"govern power nation independ principl\" \n```\n\n\n:::\n:::\n\n\n\n### Visualization of Words and Topics{-}\n\nAlthough wordclouds may not be optimal for scientific purposes they can provide a quick visual overview of a set of terms. Let's look at some topics as wordcloud.\n\nIn the following code, you can change the variable **topicToViz** with values between 1 and 20 to display other topics.\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# visualize topics as word cloud\n# choose topic of interest by a term contained in its name\ntopicToViz <- grep(\"mexico\", topicNames)[1]\n# select to 50 most probable terms from the topic by sorting the term-topic-probability vector in decreasing order\ntop50terms <- sort(tmResult$terms[topicToViz, ], decreasing = TRUE)[1:50]\nwords <- names(top50terms)\n# extract the probabilities of each of the 50 terms\nprobabilities <- sort(tmResult$terms[topicToViz, ], decreasing = TRUE)[1:50]\n# visualize the terms as wordcloud\nmycolors <- brewer.pal(8, \"Dark2\")\nwordcloud(words, probabilities, random.order = FALSE, color = mycolors)\n```\n\n::: {.cell-output-display}\n![](topic_files/figure-html/wordcloud-1.png){fig-align='center' width=384}\n:::\n:::\n\n\n\nLet us now look more closely at the distribution of topics within individual documents. To this end, we visualize the distribution in 3 sample documents.\n\nLet us first take a look at the contents of three sample documents:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nexampleIds <- c(2, 100, 200)\n# first 400 characters of file 2\nstringr::str_sub(txts$text[2], 1, 400)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"I embrace with great satisfaction the opportunity which now presents itself\\nof congratulating you on the present favorable prospects of our public\\naffairs. The recent accession of the important state of North Carolina to\\nthe Constitution of the United States (of which official information has\\nbeen received), the rising credit and respectability of our country, the\\ngeneral and increasing good will \"\n```\n\n\n:::\n\n```{.r .cell-code}\n# first 400 characters of file 100\nstringr::str_sub(txts$text[100], 1, 400)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"Provision is likewise requisite for the reimbursement of the loan which has\\nbeen made of the Bank of the United States, pursuant to the eleventh\\nsection of the act by which it is incorporated. In fulfilling the public\\nstipulations in this particular it is expected a valuable saving will be\\nmade.\"\n```\n\n\n:::\n\n```{.r .cell-code}\n# first 400 characters of file 200\nstringr::str_sub(txts$text[200], 1, 400)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"After many delays and disappointments arising out of the European war, the\\nfinal arrangements for fulfilling the engagements made to the Dey and\\nRegency of Algiers will in all present appearance be crowned with success,\\nbut under great, though inevitable, disadvantages in the pecuniary\\ntransactions occasioned by that war, which will render further provision\\nnecessary. The actual liberation of all \"\n```\n\n\n:::\n:::\n\n\n\nAfter looking into the documents, we visualize the topic distributions within the documents.\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nN <- length(exampleIds) # Number of example documents\n\n# Get topic proportions from example documents\ntopicProportionExamples <- theta[exampleIds, ]\ncolnames(topicProportionExamples) <- topicNames\n\n# Reshape data for visualization\nreshape2::melt(\n  cbind(data.frame(topicProportionExamples),\n    document = factor(1:N)\n  ),\n  variable.name = \"topic\",\n  id.vars = \"document\"\n) %>%\n  # create bar plot using ggplot2\n  ggplot(aes(topic, value, fill = document), ylab = \"Proportion\") +\n  # plot bars\n  geom_bar(stat = \"identity\") +\n  # rotate x-axis labels\n  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +\n  # flip coordinates to create horizontal bar plot\n  coord_flip() +\n  # facet by document\n  facet_wrap(~document, ncol = N)\n```\n\n::: {.cell-output-display}\n![](topic_files/figure-html/vis2-1.png){fig-align='center' width=960}\n:::\n:::\n\n\n\n### Topic distributions{-}\n\nThe figure above illustrates how topics are distributed within a document according to the model. In the current model, all three documents exhibit at least a small percentage of each topic.\n\nThe topic distribution within a document can be controlled using the *alpha* parameter of the model. Higher alpha priors result in an even distribution of topics within a document, while lower alpha priors ensure that the inference process concentrates the probability mass on a few topics for each document.\n\nIn the previous model calculation, the alpha prior was automatically estimated to fit the data, achieving the highest overall probability for the model. However, this automatic estimate may not align with the results that an analyst desires. Depending on our analysis goals, we might prefer a more concentrated (peaky) or more evenly distributed set of topics in the model.\n\nNext, let us change the alpha prior to a lower value to observe how this adjustment affects the topic distributions in the model. To do this, we first extarct the alpha value of teh previous model.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# see alpha from previous model\nattr(topicModel, \"alpha\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 2.5\n```\n\n\n:::\n:::\n\n\nThe alpha value of the previous model was `attr(topicModel, \"alpha\")`. So now, we set a much lower value (0.2) when we generate a new model. \n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# generate new LDA model with low alpha\ntopicModel2 <- LDA(DTM, K,\n  method = \"Gibbs\",\n  control = list(iter = 500, verbose = 25, alpha = 0.2)\n)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nK = 20; V = 4472; M = 8811\nSampling 500 iterations!\nIteration 25 ...\nIteration 50 ...\nIteration 75 ...\nIteration 100 ...\nIteration 125 ...\nIteration 150 ...\nIteration 175 ...\nIteration 200 ...\nIteration 225 ...\nIteration 250 ...\nIteration 275 ...\nIteration 300 ...\nIteration 325 ...\nIteration 350 ...\nIteration 375 ...\nIteration 400 ...\nIteration 425 ...\nIteration 450 ...\nIteration 475 ...\nIteration 500 ...\nGibbs sampling completed!\n```\n\n\n:::\n\n```{.r .cell-code}\n# save results\ntmResult <- posterior(topicModel2)\n# save theta values\ntheta <- tmResult$topics\n# save beta values\nbeta <- tmResult$terms\n# reset topic names\ntopicNames <- apply(terms(topicModel, 5), 2, paste, collapse = \" \")\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ntopicNames <- apply(terms(topicModel, 5), 2, paste, collapse = \" \")\ntopicNames\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                                     Topic 1 \n               \"war forc militari navi armi\" \n                                     Topic 2 \n        \"nation countri peopl everi prosper\" \n                                     Topic 3 \n     \"govern power nation independ principl\" \n                                     Topic 4 \n        \"state constitut power repres union\" \n                                     Topic 5 \n            \"act congress last made session\" \n                                     Topic 6 \n                   \"may upon duti shall law\" \n                                     Topic 7 \n\"congress subject recommend consider attent\" \n                                     Topic 8 \n            \"new great line construct pacif\" \n                                     Topic 9 \n        \"state territori indian mexico unit\" \n                                    Topic 10 \n   \"year amount expenditur increas treasuri\" \n                                    Topic 11 \n       \"import duti countri increas product\" \n                                    Topic 12 \n                 \"land public work made use\" \n                                    Topic 13 \n      \"depart report offic servic secretari\" \n                                    Topic 14 \n       \"relat govern continu countri friend\" \n                                    Topic 15 \n              \"object can great may without\" \n                                    Topic 16 \n            \"citizen law case govern person\" \n                                    Topic 17 \n               \"can must peopl everi condit\" \n                                    Topic 18 \n             \"bank govern public money issu\" \n                                    Topic 19 \n            \"govern treati unit state claim\" \n                                    Topic 20 \n        \"state unit american commerc vessel\" \n```\n\n\n:::\n:::\n\n\n\n\n\nNow visualize the topic distributions in the three documents again. What are the differences in the distribution structure?\n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# get topic proportions form example documents\ntopicProportionExamples <- theta[exampleIds, ]\ncolnames(topicProportionExamples) <- topicNames\nvizDataFrame <- reshape2::melt(\n  cbind(data.frame(topicProportionExamples),\n    document = factor(1:N)\n  ),\n  variable.name = \"topic\",\n  id.vars = \"document\"\n)\n# plot alpha distribution\nggplot(data = vizDataFrame, aes(topic, value, fill = document), ylab = \"proportion\") +\n  geom_bar(stat = \"identity\") +\n  theme(axis.text.x = element_text(angle = 90, hjust = 1)) +\n  coord_flip() +\n  facet_wrap(~document, ncol = N)\n```\n\n::: {.cell-output-display}\n![](topic_files/figure-html/vis3-1.png){fig-align='center' width=960}\n:::\n:::\n\n\n\nThe figure above now shows that the documents are more clearly assigned to specific topics. The difference in the probability of a document belonging to a particular topic is much more distinct, indicating a stronger association between documents and their respective dominant topics.\n\nBy adjusting the alpha parameter to a lower value, we have concentrated the probability mass on fewer topics for each document. This change makes the topic distribution within documents less even and more peaked, resulting in documents being more distinctly associated with specific topics.\n\nThis adjustment can be particularly useful when analyzing data sets where we expect documents to focus on a few key themes rather than covering a broad range of topics. It allows for a clearer interpretation of the primary topics discussed in each document, enhancing the overall clarity and interpretability of the topic model.\n\n\n### Topic ranking{-}\n\nDetermining the defining topics within a collection is a crucial step in topic modeling, as it helps to organize and interpret the underlying themes effectively. There are several approaches to uncover these topics and arrange them in a meaningful order. Here, we present two different methods: **Ordering Topics by Probability** and **Counting Primary Topic Appearances**. These two approaches complement each other and, when used together, can provide a comprehensive understanding of the defining topics within a collection. By combining the probabilistic ranking with the frequency count of primary topics, we can achieve a more nuanced and accurate interpretation of the underlying themes in the data.\n\n#### Approach 1: Ordering Topics by Probability{-}\n\nThis approach involves ranking topics based on their overall probability within the given collection. By examining the distribution of words across topics and documents, we can identify which topics are more dominant and relevant. This method helps to highlight the most significant themes within the data.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# mean probabilities over all paragraphs\ntopicProportions <- colSums(theta) / nDocs(DTM)\n# assign the topic names we created before\nnames(topicProportions) <- topicNames\n# show summed proportions in decreased order\nsoP <- sort(topicProportions, decreasing = TRUE)\n# inspect ordering\npaste(round(soP, 5), \":\", names(soP))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n [1] \"0.06721 : congress subject recommend consider attent\"\n [2] \"0.06448 : can must peopl everi condit\"               \n [3] \"0.06313 : year amount expenditur increas treasuri\"   \n [4] \"0.06098 : land public work made use\"                 \n [5] \"0.06076 : may upon duti shall law\"                   \n [6] \"0.06072 : bank govern public money issu\"             \n [7] \"0.05322 : relat govern continu countri friend\"       \n [8] \"0.05276 : import duti countri increas product\"       \n [9] \"0.05151 : citizen law case govern person\"            \n[10] \"0.05042 : state constitut power repres union\"        \n[11] \"0.04691 : state unit american commerc vessel\"        \n[12] \"0.04573 : state territori indian mexico unit\"        \n[13] \"0.04453 : war forc militari navi armi\"               \n[14] \"0.04368 : new great line construct pacif\"            \n[15] \"0.04282 : act congress last made session\"            \n[16] \"0.04263 : object can great may without\"              \n[17] \"0.04099 : govern treati unit state claim\"            \n[18] \"0.03731 : nation countri peopl everi prosper\"        \n[19] \"0.03646 : depart report offic servic secretari\"      \n[20] \"0.03374 : govern power nation independ principl\"     \n```\n\n\n:::\n:::\n\n\n\nWe recognize some topics that are way more likely to occur in the corpus than others. These describe rather general thematic coherence. Other topics correspond more to specific contents. \n\n#### Approach 2: Counting Primary Topic Appearances{-}\n\nAnother method is to count how often a topic appears as the primary topic within individual paragraphs or documents. This approach focuses on the frequency with which each topic takes precedence in the text, providing insight into which topics are most commonly addressed and therefore, potentially more important.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncountsOfPrimaryTopics <- rep(0, K)\nnames(countsOfPrimaryTopics) <- topicNames\nfor (i in 1:nDocs(DTM)) {\n  topicsPerDoc <- theta[i, ] # select topic distribution for document i\n  # get first element position from ordered list\n  primaryTopic <- order(topicsPerDoc, decreasing = TRUE)[1]\n  countsOfPrimaryTopics[primaryTopic] <- countsOfPrimaryTopics[primaryTopic] + 1\n}\n# sort by primary topic\nso <- sort(countsOfPrimaryTopics, decreasing = TRUE)\n# show ordering\npaste(so, \":\", names(so))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n [1] \"708 : year amount expenditur increas treasuri\"   \n [2] \"684 : congress subject recommend consider attent\"\n [3] \"630 : may upon duti shall law\"                   \n [4] \"529 : bank govern public money issu\"             \n [5] \"521 : can must peopl everi condit\"               \n [6] \"491 : import duti countri increas product\"       \n [7] \"482 : relat govern continu countri friend\"       \n [8] \"472 : land public work made use\"                 \n [9] \"425 : new great line construct pacif\"            \n[10] \"424 : citizen law case govern person\"            \n[11] \"389 : state unit american commerc vessel\"        \n[12] \"382 : state territori indian mexico unit\"        \n[13] \"378 : war forc militari navi armi\"               \n[14] \"377 : state constitut power repres union\"        \n[15] \"368 : act congress last made session\"            \n[16] \"365 : object can great may without\"              \n[17] \"342 : nation countri peopl everi prosper\"        \n[18] \"315 : govern treati unit state claim\"            \n[19] \"273 : depart report offic servic secretari\"      \n[20] \"256 : govern power nation independ principl\"     \n```\n\n\n:::\n:::\n\n\n\nSorting topics by the Rank-1 method highlights topics with specific thematic coherences, placing them at the upper ranks of the list. This sorting approach is valuable for several subsequent analysis steps:\n\n* *Semantic Interpretation of Topics*: By examining topics ranked higher in the list, researchers can gain insights into the most salient and distinctive themes present in the collection. Understanding these topics facilitates their semantic interpretation and allows for deeper exploration of the underlying content.\n\n* *Analysis of Time Series*: Examining the temporal evolution of the most important topics over time can reveal trends, patterns, and shifts in discourse. Researchers can track how the prominence of certain topics fluctuates over different time periods, providing valuable context for understanding changes in the subject matter.\n\n* *Filtering Based on Sub-Topics*: The sorted list of topics can serve as a basis for filtering the original collection to focus on specific sub-topics of interest. Researchers can selectively extract documents or passages related to particular themes, enabling targeted analysis and investigation of niche areas within the broader context.\n\nBy leveraging the Rank-1 method to sort topics, researchers can enhance their understanding of the thematic landscape within the collection and facilitate subsequent analytical tasks aimed at extracting meaningful insights and knowledge.\n\n### Filtering documents{-}\n\nThe inclusion of topic probabilities for each document or paragraph in a topic model enables its application for thematic filtering of a collection. This filtering process involves selecting only those documents that surpass a predetermined threshold of probability for specific topics. For instance, we may choose to retain documents containing a particular topic, such as topic 'X', with a probability exceeding 20 percent.\n\nIn the subsequent steps, we will implement this filtering approach to select documents based on their topical content and visualize the resulting document distribution over time. This analysis will provide insights into the prevalence and distribution of specific themes within the collection, allowing for a more targeted exploration of relevant topics across different temporal intervals.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# selected by a term in the topic name (e.g. 'militari')\ntopicToFilter <- grep(\"militari\", topicNames)[1]\ntopicThreshold <- 0.2\nselectedDocumentIndexes <- which(theta[, topicToFilter] >= topicThreshold)\nfilteredCorpus <- txts$text[selectedDocumentIndexes]\n# show length of filtered corpus\nlength(filteredCorpus)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 578\n```\n\n\n:::\n\n```{.r .cell-code}\n# show first 5 paragraphs\nhead(filteredCorpus, 5)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] \"The interests of the United States require that our intercourse with other\\nnations should be facilitated by such provisions as will enable me to\\nfulfill my duty in that respect in the manner which circumstances may\\nrender most conducive to the public good, and to this end that the\\ncompensation to be made to the persons who may be employed should,\\naccording to the nature of their appointments, be defined by law, and a\\ncompetent fund designated for defraying the expenses incident to the\\nconduct of foreign affairs.\"                                                                \n[2] \"Your attention seems to be not less due to that particular branch of our\\ntrade which belongs to the Mediterranean. So many circumstances unite in\\nrendering the present state of it distressful to us that you will not think\\nany deliberations misemployed which may lead to its relief and protection.\"                                                                                                                                                                                                                                                                                                 \n[3] \"The laws you have already passed for the establishment of a judiciary\\nsystem have opened the doors of justice to all descriptions of persons. You\\nwill consider in your wisdom whether improvements in that system may yet be\\nmade, and particularly whether an uniform process of execution on sentences\\nissuing from the Federal courts be not desirable through all the States.\"                                                                                                                                                                                                                      \n[4] \"The patronage of our commerce, of our merchants and sea men, has called for\\nthe appointment of consuls in foreign countries. It seems expedient to\\nregulate by law the exercise of that jurisdiction and those functions which\\nare permitted them, either by express convention or by a friendly\\nindulgence, in the places of their residence. The consular convention, too,\\nwith His Most Christian Majesty has stipulated in certain cases the aid of\\nthe national authority to his consuls established here. Some legislative\\nprovision is requisite to carry these stipulations into full effect.\"\n[5] \"\\\"In vain may we expect peace with the Indians on our frontiers so long as a\\nlawless set of unprincipled wretches can violate the rights of hospitality,\\nor infringe the most solemn treaties, without receiving the punishment they\\nso justly merit.\\\"\"                                                                                                                                                                                                                                                                                                                                                  \n```\n\n\n:::\n:::\n\n\n\nOur filtered corpus contains 578 documents related to the topic 1 to at least 20 %.\n\n### Topic proportions over time{-}\n\nIn the final step, we offer a comprehensive overview of the topics present in the data across different time periods. To achieve this, we aggregate the mean topic proportions per decade for all State of the Union (SOTU) speeches. These aggregated topic proportions provide a distilled representation of the prevalent themes over time and can be effectively visualized, such as through a bar plot. This visualization offers valuable insights into the evolving discourse captured within the SOTU speeches, highlighting overarching trends and shifts in thematic emphasis across decades. \n\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# append decade information for aggregation\ntextdata$decade <- paste0(substr(textdata$date, 0, 3), \"0\")\n# get mean topic proportions per decade\ntopic_proportion_per_decade <- aggregate(theta, by = list(decade = textdata$decade), mean)\n# set topic names to aggregated columns\ncolnames(topic_proportion_per_decade)[2:(K + 1)] <- topicNames\n# reshape data frame and generate plot\nreshape2::melt(topic_proportion_per_decade, id.vars = \"decade\") %>%\n  ggplot(aes(x = decade, y = value, fill = variable)) +\n  geom_bar(stat = \"identity\") +\n  labs(y = \"Proportion\", x = \"Decade\") +\n  scale_fill_manual(values = rev(colorRampPalette(brewer.pal(8, \"RdBu\"))(20))) +\n  theme(axis.text.x = element_text(angle = 90, hjust = 1))\n```\n\n::: {.cell-output-display}\n![](topic_files/figure-html/vis4-1.png){fig-align='center' width=864}\n:::\n:::\n\n\n\nThe visualization shows that topics around the relation between the federal government and the states as well as inner conflicts clearly dominate the first decades. Security issues and the economy are the most important topics of recent SOTU addresses.\n\n# Citation & Session Info {-}\n\nSchweinberger, Martin. 2024. *Topic Modeling with R*. Brisbane: The University of Queensland. url: https://slcladal.github.io/topic.html (Version 2024.05.17).\n\n\n```\n@manual{schweinberger2024topic,\n  author = {Schweinberger, Martin},\n  title = {Topic Modeling with R},\n  note = {https://ladal.edu.au/topic.html},\n  year = {2024},\n  organization = \"The University of Queensland, Australia. School of Languages and Cultures},\n  address = {Brisbane},\n  edition = {2024.05.17}\n}\n```\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsessionInfo()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nR version 4.4.1 (2024-06-14)\nPlatform: aarch64-apple-darwin20\nRunning under: macOS Sonoma 14.6.1\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRblas.0.dylib \nLAPACK: /Library/Frameworks/R.framework/Versions/4.4-arm64/Resources/lib/libRlapack.dylib;  LAPACK version 3.12.0\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\ntime zone: Australia/Brisbane\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n [1] wordcloud_2.6      topicmodels_0.2-17 tm_0.7-14          NLP_0.3-0         \n [5] tidytext_0.4.2     tidyr_1.3.1        stringr_1.5.1      slam_0.1-54       \n [9] reshape2_1.4.4     RColorBrewer_1.1-3 quanteda_4.1.0     ldatuning_1.0.2   \n[13] lda_1.5.2          ggplot2_3.5.1      flextable_0.9.7    dplyr_1.1.4       \n\nloaded via a namespace (and not attached):\n [1] fastmatch_1.1-4         gtable_0.3.6            xfun_0.49              \n [4] htmlwidgets_1.6.4       seededlda_1.4.1         lattice_0.22-6         \n [7] vctrs_0.6.5             tools_4.4.1             generics_0.1.3         \n[10] stats4_4.4.1            parallel_4.4.1          klippy_0.0.0.9500      \n[13] tibble_3.2.1            fansi_1.0.6             janeaustenr_1.0.0      \n[16] tokenizers_0.3.0        pkgconfig_2.0.3         Matrix_1.7-1           \n[19] data.table_1.16.2       assertthat_0.2.1        uuid_1.2-1             \n[22] lifecycle_1.0.4         farver_2.1.2            compiler_4.4.1         \n[25] textshaping_0.4.0       munsell_0.5.1           codetools_0.2-20       \n[28] fontquiver_0.2.1        fontLiberation_0.1.0    SnowballC_0.7.1        \n[31] htmltools_0.5.8.1       pillar_1.9.0            openssl_2.2.2          \n[34] fontBitstreamVera_0.1.1 stopwords_2.3           tidyselect_1.2.1       \n[37] zip_2.3.1               digest_0.6.37           stringi_1.8.4          \n[40] purrr_1.0.2             labeling_0.4.3          fastmap_1.2.0          \n[43] grid_4.4.1              colorspace_2.1-1        cli_3.6.3              \n[46] magrittr_2.0.3          utf8_1.2.4              withr_3.0.2            \n[49] gdtools_0.4.0           scales_1.3.0            rmarkdown_2.28         \n[52] officer_0.6.7           proxyC_0.4.1            askpass_1.2.1          \n[55] ragg_1.3.3              modeltools_0.2-23       evaluate_1.0.1         \n[58] knitr_1.48              rlang_1.1.4             Rcpp_1.0.13            \n[61] glue_1.8.0              xml2_1.3.6              jsonlite_1.8.9         \n[64] R6_2.5.1                plyr_1.8.9              systemfonts_1.1.0      \n```\n\n\n:::\n:::\n\n\n\n\n\n***\n\n[Back to top](#introduction)\n\n[Back to HOME](https://ladal.edu.au)\n\n***\n\n\n# References{-}\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<script src=\"../../site_libs/clipboard-1.7.1/clipboard.min.js\"></script>\n<link href=\"../../site_libs/primer-tooltips-1.4.0/build.css\" rel=\"stylesheet\" />\n<link href=\"../../site_libs/klippy-0.0.0.9500/css/klippy.min.css\" rel=\"stylesheet\" />\n<script src=\"../../site_libs/klippy-0.0.0.9500/js/klippy.min.js\"></script>\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}